{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b3a70e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopandas in c:\\users\\asher\\documents\\uw_mad\\geog575\\unit-2\\.venv\\lib\\site-packages (0.14.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\asher\\documents\\uw_mad\\geog575\\unit-2\\.venv\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\asher\\documents\\uw_mad\\geog575\\unit-2\\.venv\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: folium in c:\\users\\asher\\documents\\uw_mad\\geog575\\unit-2\\.venv\\lib\\site-packages (0.15.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\asher\\documents\\uw_mad\\geog575\\unit-2\\.venv\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: fiona>=1.8.21 in c:\\users\\asher\\documents\\uw_mad\\geog575\\unit-2\\.venv\\lib\\site-packages (from geopandas) (1.9.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\asher\\documents\\uw_mad\\geog575\\unit-2\\.venv\\lib\\site-packages (from geopandas) (23.2)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in c:\\users\\asher\\documents\\uw_mad\\geog575\\unit-2\\.venv\\lib\\site-packages (from geopandas) (3.6.1)\n",
      "Requirement already satisfied: shapely>=1.8.0 in c:\\users\\asher\\documents\\uw_mad\\geog575\\unit-2\\.venv\\lib\\site-packages (from geopandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asher\\documents\\uw_mad\\geog575\\unit-2\\.venv\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asher\\documents\\uw_mad\\geog575\\unit-2\\.venv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\asher\\documents\\uw_mad\\geog575\\unit-2\\.venv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\asher\\documents\\uw_mad\\geog575\\unit-2\\.venv\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\asher\\documents\\uw_mad\\geog575\\unit-2\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\asher\\documents\\uw_mad\\geog575\\unit-2\\.venv\\lib\\site-packages (from matplotlib) (4.48.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\asher\\documents\\uw_mad\\geog575\\unit-2\\.venv\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\asher\\documents\\uw_mad\\geog575\\unit-2\\.venv\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\asher\\documents\\uw_mad\\geog575\\unit-2\\.venv\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: branca>=0.6.0 in c:\\users\\asher\\documents\\uw_mad\\geog575\\unit-2\\.venv\\lib\\site-packages (from folium) (0.7.1)\n",
      "Requirement already satisfied: jinja2>=2.9 in c:\\users\\asher\\documents\\uw_mad\\geog575\\unit-2\\.venv\\lib\\site-packages (from folium) (3.1.3)\n",
      "Requirement already satisfied: requests in c:\\users\\asher\\documents\\uw_mad\\geog575\\unit-2\\.venv\\lib\\site-packages (from folium) (2.31.0)\n",
      "Requirement already satisfied: xyzservices in c:\\users\\asher\\documents\\uw_mad\\geog575\\unit-2\\.venv\\lib\\site-packages (from folium) (2023.10.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\asher\\documents\\uw_mad\\geog575\\unit-2\\.venv\\lib\\site-packages (from fiona>=1.8.21->geopandas) (23.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\asher\\documents\\uw_mad\\geog575\\unit-2\\.venv\\lib\\site-packages (from fiona>=1.8.21->geopandas) (2024.2.2)\n",
      "Requirement already satisfied: click~=8.0 in c:\\users\\asher\\documents\\uw_mad\\geog575\\unit-2\\.venv\\lib\\site-packages (from fiona>=1.8.21->geopandas) (8.1.7)\n",
      "Requirement already satisfied: click-plugins>=1.0 in c:\\users\\asher\\documents\\uw_mad\\geog575\\unit-2\\.venv\\lib\\site-packages (from fiona>=1.8.21->geopandas) (1.1.1)\n",
      "Requirement already satisfied: cligj>=0.5 in c:\\users\\asher\\documents\\uw_mad\\geog575\\unit-2\\.venv\\lib\\site-packages (from fiona>=1.8.21->geopandas) (0.7.2)\n",
      "Requirement already satisfied: six in c:\\users\\asher\\documents\\uw_mad\\geog575\\unit-2\\.venv\\lib\\site-packages (from fiona>=1.8.21->geopandas) (1.16.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asher\\documents\\uw_mad\\geog575\\unit-2\\.venv\\lib\\site-packages (from fiona>=1.8.21->geopandas) (65.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asher\\documents\\uw_mad\\geog575\\unit-2\\.venv\\lib\\site-packages (from jinja2>=2.9->folium) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asher\\documents\\uw_mad\\geog575\\unit-2\\.venv\\lib\\site-packages (from requests->folium) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asher\\documents\\uw_mad\\geog575\\unit-2\\.venv\\lib\\site-packages (from requests->folium) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asher\\documents\\uw_mad\\geog575\\unit-2\\.venv\\lib\\site-packages (from requests->folium) (2.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\asher\\documents\\uw_mad\\geog575\\unit-2\\.venv\\lib\\site-packages (from click~=8.0->fiona>=1.8.21->geopandas) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install geopandas pandas matplotlib folium numpy\n",
    "\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np # linear algebra\n",
    "import seaborn as sns\n",
    "from subprocess import check_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4afc0e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the directory! Here's what's inside:\n",
      "['CrimeData-00-2018.csv', 'CrimeData-2015.csv', 'CrimeData-2016.csv', 'CrimeData-2018.csv', 'CrimeData-2019.csv', 'CrimeData-2020.csv', 'CrimeData-2021.csv', 'CrimeData-2022.csv', 'CrimeData-2023.csv', 'merged_crimes.csv', 'Neighborhood_Boundaries.cpg', 'Neighborhood_Boundaries.dbf', 'Neighborhood_Boundaries.geojson', 'Neighborhood_Boundaries.prj', 'Neighborhood_Boundaries.shp', 'Neighborhood_Boundaries.shx']\n",
      "                       Address Case Number Crime Against  Neighborhood  Number of Records Occur Date Occur Month Year  Occur Time  Offense Category  Offense Count              Offense Type  OpenDataLat  OpenDataLon  OpenDataX  OpenDataY Report Date ReportMonthYear CaseNumber CrimeAgainst OccurDate  OccurTime OffenseCategory OffenseType ReportDate  OffenseCount\n",
      "0    3600 BLOCK OF SE KNAPP ST   17-902332      Property  Eastmoreland                1.0  2/20/2017         2/1/2017         0.0  Larceny Offenses            1.0  Theft From Motor Vehicle    45.470545  -122.625298  7656952.0   664817.0   2/20/2017   February 2017        NaN          NaN       NaN        NaN             NaN         NaN        NaN           NaN\n",
      "1  3600 BLOCK OF SE LAMBERT ST   17-902346      Property  Eastmoreland                1.0  2/20/2017         2/1/2017        30.0  Larceny Offenses            1.0  Theft From Motor Vehicle    45.467028  -122.625272  7656925.0   663535.0   2/20/2017   February 2017        NaN          NaN       NaN        NaN             NaN         NaN        NaN           NaN\n",
      "2    7200 BLOCK OF SE 32ND AVE   17-902450      Property  Eastmoreland                1.0  2/21/2017         2/1/2017      2345.0  Larceny Offenses            1.0  Theft From Motor Vehicle    45.471859  -122.630327  7655675.0   665330.0   2/22/2017   February 2017        NaN          NaN       NaN        NaN             NaN         NaN        NaN           NaN\n"
     ]
    }
   ],
   "source": [
    "#Ensure that the data is in the correct directory\n",
    "data_path = \"data/crime/\"\n",
    "if os.path.exists(data_path):\n",
    "    print(\"Found the directory! Here's what's inside:\")\n",
    "    print(os.listdir(data_path))\n",
    "else:\n",
    "    print(\"Directory not found. Check your map and compass!\")\n",
    "\n",
    "# Assuming the directory exists, let's proceed to load the files\n",
    "file_names = [\n",
    "    \"CrimeData-00-2018.csv\",\n",
    "    \"CrimeData-2018.csv\",\n",
    "    \"CrimeData-2019.csv\",\n",
    "    \"CrimeData-2020.csv\",\n",
    "    \"CrimeData-2021.csv\",\n",
    "    \"CrimeData-2022.csv\",\n",
    "    \"CrimeData-2023.csv\"\n",
    "]\n",
    "\n",
    "# Correctly construct the full file paths\n",
    "all_files = [os.path.join(data_path, file_name) for file_name in file_names]\n",
    "\n",
    "# Load and concatenate the CSV files into a single DataFrame\n",
    "try:\n",
    "    crimes = pd.concat((pd.read_csv(f) for f in all_files))\n",
    "    # Display the first three rows to verify the data\n",
    "    print(crimes.head(3))\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading files: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c696efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asher\\AppData\\Local\\Temp\\ipykernel_22912\\532167503.py:14: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  crimes['Occur_timestamp'] = pd.to_datetime(crimes['OccurDate'] + ' ' + crimes['Occur_time'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "def int_to_strtime(d):\n",
    "    \"\"\"convert int hhmm to str HH:MM \"\"\"\n",
    "    # Ensure that the input is a string with leading zeros if necessary\n",
    "    d = '{:0>4}'.format(d)\n",
    "    (h, s) = (d[:2], d[2:])\n",
    "    timestr = h + ':' + s\n",
    "    return timestr\n",
    "\n",
    "# Ensure 'OccurTime' is treated as a string and then convert to HH:MM format\n",
    "crimes['OccurTime'] = crimes['OccurTime'].astype(str).apply(lambda x: '{:0>4}'.format(x))\n",
    "crimes['Occur_time'] = crimes['OccurTime'].apply(int_to_strtime)\n",
    "\n",
    "# Note: Adjust 'OccurDate' to match the exact case and spelling of your date column\n",
    "crimes['Occur_timestamp'] = pd.to_datetime(crimes['OccurDate'] + ' ' + crimes['Occur_time'], errors='coerce')\n",
    "\n",
    "# Extracting components\n",
    "crimes['Hour'] = crimes['Occur_timestamp'].dt.hour\n",
    "crimes['Date'] = crimes['Occur_timestamp'].dt.date\n",
    "crimes['Day_of_Week'] = crimes['Occur_timestamp'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b29d8fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Specify your desired output file name\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m output_file_path \u001b[38;5;241m=\u001b[39m \u001b[43mdata_path\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/final_crimes.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Export the DataFrame to a CSV file\u001b[39;00m\n\u001b[0;32m      5\u001b[0m crimes\u001b[38;5;241m.\u001b[39mto_csv(output_file_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_path' is not defined"
     ]
    }
   ],
   "source": [
    "# Specify your desired output file name\n",
    "output_file_path = data_path + '/final_crimes.csv'\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "crimes.to_csv(output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635b7585",
   "metadata": {},
   "source": [
    "take a look at the neighborhood names in both your crime data (CSV) and your neighborhood shapefile (GeoDataFrame) to understand the formatting and any potential inconsistencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ed0b054b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asher\\AppData\\Local\\Temp\\ipykernel_22912\\3294836310.py:2: DtypeWarning: Columns (1,2,5,6,8,10,15,16,17,18,19,20,21,22,23,26,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  crimes_df = pd.read_csv('data/crime/final_crimes.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV Names:  ['Eastmoreland' 'Eliot' 'Far Southwest' 'Forest Park' 'Foster-Powell'\n",
      " 'Glenfair' 'Goose Hollow' 'Grant Park' 'Hayden Island' 'Hazelwood'\n",
      " 'Portsmouth' 'Overlook' 'Parkrose' 'Parkrose Heights' 'Pearl' 'Piedmont'\n",
      " 'Pleasant Valley' 'Powellhurst-Gilbert' 'Reed' 'Richmond'\n",
      " 'Rose City Park' 'Roseway' 'Russell' 'Sellwood-Moreland' 'South Portland'\n",
      " 'South Tabor' 'St Johns' \"Sullivan's Gulch\" 'Sumner' 'Sunderland'\n",
      " 'Sunnyside' 'University Park' 'West Portland Park' 'Wilkes' 'Woodlawn'\n",
      " 'Woodstock' nan 'Arbor Lodge' 'Argay' 'Arnold Creek' 'Ashcreek'\n",
      " 'Beaumont-Wilshire' 'Boise' 'Brentwood-Darlington' 'Bridgeton'\n",
      " 'Bridlemile' 'Brooklyn' 'Buckman East' 'Buckman West' 'Cathedral Park'\n",
      " 'Centennial' 'Concordia' 'Creston-Kenilworth' 'Crestwood' 'Cully'\n",
      " 'Hillsdale' 'Hillside' 'Hosford-Abernethy' 'Irvington' 'Kenton' 'Kerns'\n",
      " 'King' 'Lents' 'Linnton' 'Lloyd' 'Marshall Park' 'Mill Park' 'Montavilla'\n",
      " 'Mt Scott-Arleta' 'Mt Tabor' 'North Tabor' 'Northwest'\n",
      " 'Old Town/Chinatown' 'Sabin' 'Downtown' 'Hollywood' 'Humboldt'\n",
      " 'Madison South' 'Multnomah' 'Hayhurst' 'Sylvan-Highlands' 'Alameda'\n",
      " 'Arlington Heights' 'Southwest Hills' 'Maplewood' 'Homestead'\n",
      " 'Collins View' 'East Columbia' 'Vernon' 'Laurelhurst' 'Ardenwald'\n",
      " 'Northwest Industrial' 'Woodland Park' 'Northwest Heights'\n",
      " 'South Burlingame' 'Markham' 'Healy Heights']\n",
      "SHP Names:  ['Linnton' 'Forest Park/Linnton' 'Forest Park' 'Cathedral Park'\n",
      " 'University Park' 'MC Unclaimed #14' 'Piedmont' 'Woodlawn' 'Cully'\n",
      " 'Arbor Lodge' 'Overlook' 'Concordia' 'Parkrose' 'Sumner' 'Argay Terrace'\n",
      " 'Humboldt' 'King' 'Vernon' 'Wilkes' 'Beaumont-Wilshire' 'Sabin' 'Alameda'\n",
      " 'Boise' 'Northwest Heights' 'Roseway' 'Madison South'\n",
      " 'Argay Terrace/Wilkes' 'Boise/Eliot' 'Eliot' 'Irvington'\n",
      " 'Sabin/Irvington' 'Alameda/Irvington' 'Rose City Park' 'Parkrose Heights'\n",
      " 'Northwest District' 'Alameda/Beaumont-Wilshire'\n",
      " 'Forest Park/Northwest District' 'Russell' 'Roseway/Madison South'\n",
      " 'Grant Park' 'MC Unclaimed #5' 'Pearl District' 'Grant Park/Hollywood'\n",
      " 'Hollywood' 'Woodland Park' 'Lloyd' \"Sullivan's Gulch\"\n",
      " \"Sullivan's Gulch/Grant Park\" 'Montavilla' 'Hillside/Northwest District'\n",
      " 'Laurelhurst' 'Kerns' \"Lloyd/Sullivan's Gulch\" 'Hillside' 'North Tabor'\n",
      " 'Hazelwood' 'Old Town' 'Arlington Heights' 'Goose Hollow' 'Glenfair'\n",
      " 'Arlington Heights/Sylvan-Highlands' 'Buckman' 'Portland Downtown'\n",
      " 'Mt. Tabor' 'Sylvan-Highlands' 'Goose Hollow/Southwest Hills'\n",
      " 'Southwest Hills' 'Sunnyside' 'Hazelwood/Mill Park'\n",
      " 'Sylvan-Highlands/Southwest Hills' 'Mill Park' 'Centennial'\n",
      " 'Hosford-Abernethy' 'Richmond' 'South Portland' 'Homestead' 'South Tabor'\n",
      " 'Bridlemile/Southwest Hills' 'Powellhurst-Gilbert' 'Brooklyn'\n",
      " 'Bridlemile' 'Creston-Kenilworth' 'Hillsdale' 'Foster-Powell' 'Lents'\n",
      " 'Lents/Powellhurst-Gilbert' 'Healy Heights/Southwest Hills'\n",
      " 'Centennial/Pleasant Valley' 'Pleasant Valley' 'Mt. Scott-Arleta'\n",
      " 'Sellwood-Moreland' 'Reed' 'Woodstock' 'Hayhurst' 'Eastmoreland/Reed'\n",
      " 'Eastmoreland' 'Pleasant Valley/Powellhurst-Gilbert' 'Maplewood'\n",
      " 'Multnomah' 'Brentwood-Darlington' 'South Burlingame' 'Ashcreek'\n",
      " 'MC Unclaimed #11' 'Eastmoreland/Ardenwald-Johnson Creek'\n",
      " 'Ardenwald-Johnson Creek' 'Markham' 'Marshall Park'\n",
      " 'Ardenwald-Johnson Creek/Woodstock' 'Collins View' 'Crestwood'\n",
      " 'West Portland Park' 'MC Unclaimed #13' 'Arnold Creek' 'Far Southwest'\n",
      " 'Ashcreek/Crestwood' 'St. Johns' 'Hayden Island' 'Kenton' 'Bridgeton'\n",
      " 'East Columbia' 'Sunderland' 'Portsmouth']\n"
     ]
    }
   ],
   "source": [
    "# Load crime data\n",
    "crimes_df = pd.read_csv('data/crime/final_crimes.csv')\n",
    "\n",
    "# Load neighborhood shapefile\n",
    "neighborhoods_gdf = gpd.read_file('data/crime/Neighborhood_Boundaries.shp')\n",
    "\n",
    "# Assuming 'crimes_df' is your DataFrame and 'neighborhoods_gdf' is your GeoDataFrame\n",
    "print('CSV Names: ', crimes_df['Neighborhood'].unique())\n",
    "print('SHP Names: ',  neighborhoods_gdf['MAPLABEL'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb96b4f",
   "metadata": {},
   "source": [
    "To ensure a successful match, convert all neighborhood names to a consistent case (e.g., all lowercase) and strip any leading or trailing spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73984105",
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_df['Neighborhood'] = crimes_df['Neighborhood'].str.lower().str.strip()\n",
    "neighborhoods_gdf['MAPLABEL'] = neighborhoods_gdf['MAPLABEL'].str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccbf987",
   "metadata": {},
   "source": [
    "If you notice spelling inconsistencies or variations in how neighborhood names are written, you may need to manually map these variations to a standard form. Create a dictionary to map variant spellings to a standardized spelling and apply this mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "06bbca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'neighborhood_column_in_csv' and 'neighborhood_column_in_shapefile' are the correct column names\n",
    "unique_crime_neighborhoods = set(crimes_df['Neighborhood'].unique())\n",
    "unique_shapefile_neighborhoods = set(neighborhoods_gdf['MAPLABEL'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8e1dce28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names in crime data not found in shapefile: ['ardenwald', 'argay', 'buckman east', 'buckman west', 'downtown', 'healy heights', 'mt scott-arleta', 'mt tabor', 'nan', 'northwest', 'northwest industrial', 'old town/chinatown', 'pearl', 'st johns']\n",
      "Names in shapefile not found in crime data: ['alameda/beaumont-wilshire', 'alameda/irvington', 'ardenwald-johnson creek', 'ardenwald-johnson creek/woodstock', 'argay terrace', 'argay terrace/wilkes', 'arlington heights/sylvan-highlands', 'ashcreek/crestwood', 'boise/eliot', 'bridlemile/southwest hills', 'buckman', 'centennial/pleasant valley', 'eastmoreland/ardenwald-johnson creek', 'eastmoreland/reed', 'forest park/linnton', 'forest park/northwest district', 'goose hollow/southwest hills', 'grant park/hollywood', 'hazelwood/mill park', 'healy heights/southwest hills', 'hillside/northwest district', 'lents/powellhurst-gilbert', \"lloyd/sullivan's gulch\", 'mc unclaimed #11', 'mc unclaimed #13', 'mc unclaimed #14', 'mc unclaimed #5', 'mt. scott-arleta', 'mt. tabor', 'northwest district', 'old town', 'pearl district', 'pleasant valley/powellhurst-gilbert', 'portland downtown', 'roseway/madison south', 'sabin/irvington', 'st. johns', \"sullivan's gulch/grant park\", 'sylvan-highlands/southwest hills']\n"
     ]
    }
   ],
   "source": [
    "# Names in crime data not found in shapefile\n",
    "missing_in_shapefile = unique_crime_neighborhoods - unique_shapefile_neighborhoods\n",
    "# Names in shapefile not found in crime data\n",
    "missing_in_crime_data = unique_shapefile_neighborhoods - unique_crime_neighborhoods\n",
    "\n",
    "missing_in_shapefile_sorted = sorted([str(item) for item in missing_in_shapefile])\n",
    "missing_in_crime_data_sorted = sorted([str(item) for item in missing_in_crime_data])\n",
    "\n",
    "print(\"Names in crime data not found in shapefile:\", missing_in_shapefile_sorted)\n",
    "print(\"Names in shapefile not found in crime data:\", missing_in_crime_data_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83714b16",
   "metadata": {},
   "source": [
    "Create a Mapping Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c5bfb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_mapping = {\n",
    "    'ardenwald': 'ardenwald-johnson creek',\n",
    "    'argay': 'argay terrace',\n",
    "    'buckman east': 'buckman',  # Assuming you want to merge east/west\n",
    "    'buckman west': 'buckman',  # Assuming you want to merge east/west\n",
    "    'downtown': 'portland downtown',\n",
    "    'healy heights': 'healy heights/southwest hills',\n",
    "    'mt scott-arleta': 'mt. scott-arleta',\n",
    "    'mt tabor': 'mt. tabor',\n",
    "    'northwest': 'northwest district',\n",
    "    'northwest industrial': 'northwest district',  # Assuming you want to merge; adjust based on your analysis\n",
    "    'old town/chinatown': 'old town',  # Decide based on which name is more encompassing or split entries\n",
    "    'pearl': 'pearl district',\n",
    "    'st johns': 'st. johns',\n",
    "    'nan': None  # Decide how to handle 'nan'; perhaps exclude these records or map them to a placeholder\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715188c1",
   "metadata": {},
   "source": [
    "Apply the Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c93d8cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_df['Neighborhood'] = crimes_df['Neighborhood'].map(name_mapping).fillna(crimes_df['Neighborhood'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2497be0",
   "metadata": {},
   "source": [
    "Re-check and Adjust\n",
    "After applying the initial mapping, re-check for any names that still don't match and adjust your mapping dictionary accordingly. This step might require iterating a few times to catch all discrepancies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0fd607ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names in crime data not found in shapefile: ['nan']\n",
      "Names in shapefile not found in crime data: ['alameda/beaumont-wilshire', 'alameda/irvington', 'ardenwald-johnson creek/woodstock', 'argay terrace/wilkes', 'arlington heights/sylvan-highlands', 'ashcreek/crestwood', 'boise/eliot', 'bridlemile/southwest hills', 'centennial/pleasant valley', 'eastmoreland/ardenwald-johnson creek', 'eastmoreland/reed', 'forest park/linnton', 'forest park/northwest district', 'goose hollow/southwest hills', 'grant park/hollywood', 'hazelwood/mill park', 'hillside/northwest district', 'lents/powellhurst-gilbert', \"lloyd/sullivan's gulch\", 'mc unclaimed #11', 'mc unclaimed #13', 'mc unclaimed #14', 'mc unclaimed #5', 'pleasant valley/powellhurst-gilbert', 'roseway/madison south', 'sabin/irvington', \"sullivan's gulch/grant park\", 'sylvan-highlands/southwest hills']\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'neighborhood_column_in_csv' and 'neighborhood_column_in_shapefile' are the correct column names\n",
    "unique_crime_neighborhoods = set(crimes_df['Neighborhood'].unique())\n",
    "unique_shapefile_neighborhoods = set(neighborhoods_gdf['MAPLABEL'].unique())\n",
    "# Names in crime data not found in shapefile\n",
    "missing_in_shapefile = unique_crime_neighborhoods - unique_shapefile_neighborhoods\n",
    "# Names in shapefile not found in crime data\n",
    "missing_in_crime_data = unique_shapefile_neighborhoods - unique_crime_neighborhoods\n",
    "\n",
    "missing_in_shapefile_sorted = sorted([str(item) for item in missing_in_shapefile])\n",
    "missing_in_crime_data_sorted = sorted([str(item) for item in missing_in_crime_data])\n",
    "\n",
    "print(\"Names in crime data not found in shapefile:\", missing_in_shapefile_sorted)\n",
    "print(\"Names in shapefile not found in crime data:\", missing_in_crime_data_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675aec42",
   "metadata": {},
   "source": [
    "Perform the Join and Review the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f1577125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   OBJECTID     NAME COMMPLAN SHARED COALIT HORZ_VERT    Shape_Leng MAPLABEL  ID                                           geometry                          Address Case Number Crime Against Neighborhood  Number of Records Occur Date Occur Month Year  Occur Time  Offense Category  Offense Count              Offense Type  OpenDataLat  OpenDataLon  OpenDataX  OpenDataY Report Date ReportMonthYear CaseNumber CrimeAgainst OccurDate OccurTime OffenseCategory OffenseType ReportDate  OffenseCount Occur_time Occur_timestamp  Hour Date  Day_of_Week\n",
      "0         1  LINNTON     None      N   NWNW      HORZ  53244.045538  linnton   1  POLYGON ((-13669901.863 5719574.412, -13669574...  11300 BLOCK OF NW GERMANTOWN RD   18-148935      Property      linnton                1.0   5/5/2018         5/1/2018      1600.0    Fraud Offenses            1.0            Identity Theft    45.589627  -122.790542  7615808.0   709376.0    5/5/2018        May 2018        NaN          NaN       NaN      0nan             NaN         NaN        NaN           NaN      0n:an             NaN   NaN  NaN          NaN\n",
      "1         1  LINNTON     None      N   NWNW      HORZ  53244.045538  linnton   1  POLYGON ((-13669901.863 5719574.412, -13669574...     9500 BLOCK OF NW HARBOR BLVD   18-907527      Property      linnton                1.0  5/15/2018         5/1/2018       207.0    Fraud Offenses            1.0            Identity Theft    45.589928  -122.780085  7618487.0   709410.0   5/15/2018        May 2018        NaN          NaN       NaN      0nan             NaN         NaN        NaN           NaN      0n:an             NaN   NaN  NaN          NaN\n",
      "2         1  LINNTON     None      N   NWNW      HORZ  53244.045538  linnton   1  POLYGON ((-13669901.863 5719574.412, -13669574...  11000 BLOCK OF NW GERMANTOWN RD   17-901615      Property      linnton                1.0   2/2/2017         2/1/2017       930.0  Larceny Offenses            1.0  Theft From Motor Vehicle    45.588117  -122.788496  7616316.0   708811.0    2/6/2017   February 2017        NaN          NaN       NaN      0nan             NaN         NaN        NaN           NaN      0n:an             NaN   NaN  NaN          NaN\n",
      "3         1  LINNTON     None      N   NWNW      HORZ  53244.045538  linnton   1  POLYGON ((-13669901.863 5719574.412, -13669574...     ST JOHNS BRG / NW BRIDGE AVE    17-36947      Property      linnton                1.0   2/6/2017         2/1/2017      1230.0  Larceny Offenses            1.0  Theft From Motor Vehicle    45.583164  -122.768716  7621327.0   706863.0    2/6/2017   February 2017        NaN          NaN       NaN      0nan             NaN         NaN        NaN           NaN      0n:an             NaN   NaN  NaN          NaN\n",
      "4         1  LINNTON     None      N   NWNW      HORZ  53244.045538  linnton   1  POLYGON ((-13669901.863 5719574.412, -13669574...     5900 BLOCK OF NW SALTZMAN RD   17-902401      Property      linnton                1.0  2/21/2017         2/1/2017      1330.0  Larceny Offenses            1.0  Theft From Motor Vehicle    45.562432  -122.749220  7626106.0   699167.0   2/21/2017   February 2017        NaN          NaN       NaN      0nan             NaN         NaN        NaN           NaN      0n:an             NaN   NaN  NaN          NaN\n",
      "MAPLABEL         0\n",
      "Neighborhood    32\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Perform an attribute join\n",
    "joined_gdf = neighborhoods_gdf.merge(crimes_df, how='left', left_on='MAPLABEL', right_on='Neighborhood')\n",
    "\n",
    "# Preview the first few rows\n",
    "print(joined_gdf.head())\n",
    "\n",
    "# Check for missing values in key columns, adjust column names as needed\n",
    "print(joined_gdf[['MAPLABEL', 'Neighborhood']].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71114839",
   "metadata": {},
   "source": [
    "Save as a geojson file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "af35d5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Save as GeoJSON\n",
    "joined_gdf.to_file(\"data/pdx_crime.geojson\", driver='GeoJSON')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
